# MTG Image DB - Recommended Improvements

**Document Version**: 1.3
**Date**: 2025-10-13
**Status**: In Progress

**User Priorities**: 1) Accuracy from blurry/bad images, 2) Query speed for users, 3) Browser DB size. Build time is NOT a priority.

This document tracks recommended improvements for the `mtg-image-db` package based on code review. Items are **sorted by priority** with the most critical issues first.

---

## ‚úÖ Completed Improvements

### ‚úÖ P1.1: Fix Cosine Similarity Calculation in `query_index.py`
**Completed**: 2025-10-13
**Impact**: Fixed incorrect similarity scores. Note: Rankings were unaffected for top-k queries.

### ‚úÖ P1.2: Make Query Path a CLI Argument
**Completed**: 2025-10-13
**Impact**: Script now accepts image path as argument: `python query_index.py <image_path> [--k N]`

### ‚úÖ P1.3: Add CLI Arguments to `export_for_browser.py`
**Completed**: 2025-10-13
**Impact**: Added `--input-dir` and `--output-dir` arguments with sensible defaults. Also includes output directory validation (P3.4).

---

## üü† Priority 2: User Experience Improvements

**User Priorities**: 1) Accuracy from blurry/bad images, 2) Query speed for users, 3) Browser DB size. Build time is not a concern.

**Dataset Size**: ~50k cards currently, won't exceed 60k for many years.

---

### P2.1: üî¥ HIGH PRIORITY - Use Higher Quality Images for Better Accuracy

**File**: `build_mtg_faiss.py`
**Lines**: 40-42
**Issue**: Currently prioritizes 'normal' images, but PNG images are higher quality and better for matching blurry/low-quality query images.

**User Impact**: **Directly improves accuracy from blurry images (Priority #1)**

**Proposed Solution**:
```python
def pick_card_image(uris):
    # PNG > large > normal for best quality and accuracy with blurry inputs
    return uris.get("png") or uris.get("large") or uris.get("normal") or uris.get("border_crop")
```

**Trade-offs**: 
- ‚úÖ Better feature extraction from high-quality source images
- ‚úÖ More robust matching against blurry query images
- ‚ö†Ô∏è Larger downloads during build (but build time is not a concern)

**Impact**: Significantly better accuracy, especially with poor quality query images.

**Effort**: 2 minutes

---

### P2.2: üî¥ HIGH PRIORITY - Increase Image Resolution for CLIP

**File**: `build_mtg_faiss.py`
**Lines**: 86-99, 249
**Issue**: Default `target_size=256` is conservative. CLIP can handle larger inputs and extracts better features from higher resolution.

**User Impact**: **Improves accuracy from blurry images (Priority #1)**

**Proposed Solution**:
```python
# Change default from 256 to 384
def load_image_rgb(path: Path, target_size: int = 384) -> Optional[Image.Image]:
    # ... existing code ...

# In main():
ap.add_argument("--size", type=int, default=384, help="Square resize for images before CLIP preprocess.")
```

**Trade-offs**:
- ‚úÖ Better feature extraction, especially from degraded images
- ‚úÖ More discriminative embeddings
- ‚ö†Ô∏è Slower embedding phase during build (not a concern)
- ‚ö†Ô∏è Slightly higher memory usage during build

**Impact**: 10-20% better accuracy on blurry/low-quality queries.

**Effort**: 2 minutes

---

### P2.3: üî¥ HIGH PRIORITY - Implement HNSW Index for Fast Queries

**File**: `build_mtg_faiss.py`
**Line**: 226
**Issue**: `IndexFlatIP` is brute-force O(N); slow for 50k+ cards in browser.

**User Impact**: **10-100x faster queries (Priority #2), smaller index size (Priority #3)**

**Proposed Solution**:
```python
# Build FAISS index with HNSW for speed
d = X.shape[1]

# For 50k-60k cards, HNSW provides massive speedup with minimal accuracy loss
if X.shape[0] > 10000:
    # M=64 for better recall, efConstruction=400 for high accuracy
    index = faiss.IndexHNSWFlat(d, 64)
    index.hnsw.efConstruction = 400  # Higher = better accuracy (slower build, but we don't care)
    index.add(X)
    print(f"Built HNSW index with M=64, efConstruction=400")
else:
    # Small datasets can use brute-force
    index = faiss.IndexFlatIP(d)
    index.add(X)

faiss.write_index(index, str(out_dir / "mtg_cards.faiss"))
```

**Trade-offs**:
- ‚úÖ 10-100x faster queries in browser
- ‚úÖ 30-50% smaller index file size
- ‚ö†Ô∏è ~1-2% accuracy loss (mitigated by high efConstruction=400)
- ‚ö†Ô∏è Slower build time (not a concern)

**Impact**: Enables instant queries even with 50k+ cards. Critical for browser performance.

**Effort**: 15 minutes
**SPEC Reference**: [SPEC-FR-EI-02b]

---

### P2.4: üü° MEDIUM PRIORITY - Quantize Embeddings to int8 for Browser

**File**: `export_for_browser.py`
**Lines**: 31-33
**Issue**: float16 embeddings are 2 bytes per value. int8 quantization reduces to 1 byte with minimal accuracy loss.

**User Impact**: **50% smaller browser download (Priority #3)**

**Proposed Solution**:
```python
# Export with int8 quantization
X = np.load(EMB_NPY)  # float32 [N,512], already L2-normalized

# Quantize to int8: map [-1, 1] to [-127, 127]
X_int8 = np.clip(X * 127, -127, 127).astype(np.int8)
X_int8.tofile(OUT_BIN)
print(f"Wrote {OUT_BIN} (int8 quantized)  (~{X_int8.nbytes/1e6:.1f} MB)  shape={X.shape}")

# Add metadata about quantization
meta_header = {
    "quantization": "int8",
    "scale_factor": 127,
    "shape": list(X.shape),
    "dtype": "int8"
}
```

**Browser-side dequantization**:
```javascript
// In browser: convert int8 back to float32
const embeddings = new Float32Array(int8Array.length);
for (let i = 0; i < int8Array.length; i++) {
    embeddings[i] = int8Array[i] / 127.0;
}
```

**Trade-offs**:
- ‚úÖ 50% smaller download (50k cards: ~50MB ‚Üí ~25MB)
- ‚úÖ Faster browser load time
- ‚ö†Ô∏è ~0.5-1% accuracy loss (negligible)
- ‚ö†Ô∏è Requires browser-side dequantization code

**Impact**: Significantly faster initial load, especially on mobile/slow connections.

**Effort**: 1 hour (including browser integration)

---

### P2.5: üü¢ LOW PRIORITY - Consider CLIP ViT-L/14 for Maximum Accuracy

**File**: `build_mtg_faiss.py`
**Line**: 111
**Issue**: ViT-B/32 (512-dim) is fast but ViT-L/14 (768-dim) is more accurate, especially with degraded images.

**User Impact**: **Best possible accuracy from blurry images (Priority #1)**

**Proposed Solution**:
```python
# Add model selection argument
ap.add_argument("--model", default="ViT-B/32", 
                choices=["ViT-B/32", "ViT-L/14"],
                help="CLIP model: ViT-B/32 (512-dim, fast) or ViT-L/14 (768-dim, accurate)")

# In Embedder:
self.model, self.preprocess = clip.load(model_name, device=self.device)
```

**Trade-offs**:
- ‚úÖ 10-15% better accuracy on challenging queries
- ‚úÖ Better feature extraction from blurry/degraded images
- ‚ö†Ô∏è 3x slower build time (not a concern)
- ‚ö†Ô∏è 50% larger browser download (768-dim vs 512-dim)
- ‚ö†Ô∏è Slower browser queries (~1.5x)

**Recommendation**: Test with ViT-B/32 first. Only upgrade if accuracy is insufficient, as the browser size/speed trade-off is significant.

**Impact**: Maximum accuracy, but at cost of browser performance.

**Effort**: 30 minutes

---

### ‚ùå REMOVED: Parallel Image Downloads (P2.1 - old)
**Reason**: Only improves build time, which is not a priority.

### ‚ùå REMOVED: Auto-tune Batch Size (P2.2 - old)
**Reason**: Only improves build time, which is not a priority.

---

---

## üü° Priority 3: Error Handling & Observability

Better visibility into failures and data quality issues. **Important for production use.**

### P3.1: Add Logging for Failed Downloads

**File**: `build_mtg_faiss.py`
**Lines**: 66-84
**Issue**: Silent failures when images fail to download.

**Proposed**:
```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def download_image(url: str, cache_dir: Path, retries: int = 3, timeout: int = 20) -> Optional[Path]:
    # ... existing code ...
    except Exception as e:
        if attempt == retries:
            logger.warning(f"Failed to download {url} after {retries} attempts: {e}")
            return None
        time.sleep(0.8 * attempt)
```

**Impact**: Better debugging, visibility into data quality issues.

**Effort**: 20 minutes

---

### P3.2: Add Summary Statistics After Build

**File**: `build_mtg_faiss.py`
**Line**: 238 (end of build_index)
**Issue**: No summary of success/failure rates.

**Proposed**:
```python
# At end of build_index()
failed_downloads = sum(1 for p in paths if p is None)
failed_embeddings = len(records) - X.shape[0]

print("\n=== Build Summary ===")
print(f"Total records: {len(records):,}")
print(f"Failed downloads: {failed_downloads:,} ({failed_downloads/len(records)*100:.1f}%)")
print(f"Failed embeddings: {failed_embeddings:,} ({failed_embeddings/len(records)*100:.1f}%)")
print(f"Successfully indexed: {X.shape[0]:,} ({X.shape[0]/len(records)*100:.1f}%)")
```

**Impact**: Data quality visibility.

**Effort**: 10 minutes

---

### P3.3: Validate Downloaded Images

**File**: `build_mtg_faiss.py`
**Line**: 79
**Issue**: No validation that downloaded file is a valid image.

**Proposed**:
```python
from PIL import Image

def download_image(url: str, cache_dir: Path, retries: int = 3, timeout: int = 20) -> Optional[Path]:
    # ... after download ...
    with open(fp, "wb") as f:
        for chunk in r.iter_content(1 << 14):
            if chunk:
                f.write(chunk)

    # Validate it's a real image
    try:
        Image.open(fp).verify()
        return fp
    except Exception:
        fp.unlink()  # Delete corrupt file
        return None
```

**Impact**: Prevents corrupt cache files.

**Effort**: 10 minutes

---

### P3.4: Add Output Directory Validation

**File**: `export_for_browser.py`
**Lines**: 10-12
**Issue**: No check that output directory is writable.

**Proposed**:
```python
def main():
    OUT_BIN.parent.mkdir(parents=True, exist_ok=True)

    if not OUT_BIN.parent.is_dir():
        raise SystemExit(f"Output directory {OUT_BIN.parent} is not accessible")

    # ... rest of function
```

**Impact**: Clearer error messages.

**Effort**: 5 minutes

---

## üîµ Priority 4: Code Quality & Maintainability

Reduce technical debt and improve long-term maintainability. **Implement when stabilizing.**

### P4.1: Extract Device Selection to Shared Utility

**Files**: `build_mtg_faiss.py` (lines 104-110), `query_index.py` (lines 14-16)
**Issue**: Duplicated device selection logic.

**Proposed**: Create `utils.py`:
```python
import torch

def get_best_device() -> str:
    """Select best available device: MPS > CUDA > CPU."""
    if torch.backends.mps.is_available():
        return "mps"
    elif torch.cuda.is_available():
        return "cuda"
    return "cpu"
```

**Impact**: DRY principle, easier to maintain.

**Effort**: 15 minutes

---

### P4.2: Add Type Hints Throughout

**Files**: All Python files
**Issue**: Missing return type hints on many functions.

**Example**:
```python
# Before
def load_bulk(kind: str):
    ...

# After
def load_bulk(kind: str) -> List[dict]:
    ...
```

**Impact**: Better IDE support, catches type errors early.

**Effort**: 1-2 hours for full coverage

---

### P4.3: Make Image Preference Configurable

**File**: `build_mtg_faiss.py`
**Line**: 40-42
**Issue**: Hardcoded image quality preference.

**Proposed**:
```python
def pick_card_image(uris, preference=None):
    """Select best available image URL.

    Args:
        uris: Dict of image URIs from Scryfall
        preference: List of preferred keys in order, e.g. ['png', 'normal']
    """
    if preference is None:
        preference = ['normal', 'border_crop', 'png', 'large']

    for key in preference:
        if key in uris:
            return uris[key]
    return None
```

**Impact**: Flexibility for different use cases (quality vs. speed).

**Effort**: 15 minutes

---

## ‚ö™ Priority 5: Testing & Verification

Automated testing for reliability. **Essential before production deployment.**

### P5.1: Add Unit Tests for Core Functions

**New File**: `tests/test_build.py`
**Issue**: No automated tests.

**Proposed Coverage**:
- `face_image_urls()` - handles single/double-faced cards correctly
- `safe_filename()` - generates stable cache names
- `load_image_rgb()` - handles corrupt images gracefully
- Device selection utility

**Framework**: `pytest`

**Effort**: 2-3 hours for initial test suite

---

### P5.2: Add Integration Test for Full Pipeline

**New File**: `tests/test_integration.py`
**Issue**: No end-to-end verification.

**Proposed**:
```python
def test_full_pipeline_small_dataset():
    """Test build ‚Üí export ‚Üí query with --limit 100"""
    # 1. Build with small limit
    # 2. Export for browser
    # 3. Query and verify results
    # 4. Clean up
```

**Effort**: 1 hour

---

### P5.3: Add Data Validation Script

**New File**: `scripts/validate_index.py`
**Purpose**: Verify index integrity after build.

**Checks**:
- Embedding count matches metadata count
- All embeddings are L2-normalized
- No NaN/Inf values
- FAISS index is searchable
- Browser export files exist and match

**Effort**: 1 hour

---

## ‚ö´ Priority 6: Configuration & Flexibility

Advanced configuration options. **Nice-to-have for power users.**

### P6.1: Add YAML Configuration File Support

**New File**: `config.yml`
**Issue**: Many parameters scattered across CLI args.

**Proposed**:
```yaml
# config.yml
data:
  kind: unique_artwork
  limit: null  # null = no limit

paths:
  cache: image_cache
  output: index_out

embedding:
  batch_size: 64
  target_size: 256
  device: auto  # auto, cpu, cuda, mps

download:
  retries: 3
  timeout: 20
  max_workers: 10
  image_preference:
    - normal
    - border_crop
    - png
    - large

index:
  use_hnsw: auto  # auto, true, false
  hnsw_m: 32
  hnsw_ef_construction: 200
```

**Effort**: 2 hours (including argparse integration)

---

### P6.2: Add Resume/Incremental Build Support

**File**: `build_mtg_faiss.py`
**Issue**: No way to resume interrupted builds.

**Proposed**:
- Save checkpoint after download phase
- Save checkpoint after embedding phase
- Add `--resume` flag to continue from checkpoint

**Impact**: Saves hours on interrupted builds.

**Effort**: 3-4 hours

---

## üìù Priority 7: Documentation Improvements

Better user guidance and onboarding. **Helpful for new contributors.**

### P7.1: Add Troubleshooting Section to README

**File**: `README.md`
**Topics to Cover**:
- Scryfall API rate limiting
- What to do if API is down
- Handling out-of-memory errors
- Network timeout issues
- Corrupt cache recovery

**Effort**: 30 minutes

---

### P7.2: Add Performance Benchmarks

**File**: `README.md` or new `BENCHMARKS.md`
**Content**:
- Expected runtime for full dataset (CPU/GPU/MPS)
- Memory requirements
- Disk space requirements
- Query performance metrics

**Effort**: 1 hour (requires running benchmarks)

---

### P7.3: Document Browser Integration

**File**: `README.md`
**Issue**: References `index.html` but unclear where it lives.

**Action**: Clarify that browser UI is in `apps/web` and link to web app docs.

**Effort**: 10 minutes

---

## üîß Priority 8: Dependency Management

Reproducible builds and environment stability. **Important for team collaboration.**

### P8.1: Pin CLIP Commit in Conda Environments

**Files**: `environment-*.yml`
**Issue**: Using `git+https://github.com/openai/CLIP.git` without commit hash.

**Current**:
```yaml
- git+https://github.com/openai/CLIP.git
```

**Proposed**:
```yaml
- git+https://github.com/openai/CLIP.git@a1d4862
```

**Impact**: Reproducible builds across time.

**Effort**: 5 minutes

---

### P8.2: Add Conda Lock Files

**New Files**: `conda-lock.yml` (per environment)
**Purpose**: Fully reproducible environments.

**Tool**: `conda-lock`

**Effort**: 30 minutes setup + documentation

---

## üí° Priority 9: Nice-to-Have Features

Future enhancements and quality-of-life improvements. **Implement when time permits.**

### P9.1: Docker Support

**New File**: `Dockerfile`
**Purpose**: Reproducible environment without Conda.

**Effort**: 2-3 hours

---

### P9.2: Pre-commit Hooks

**New File**: `.pre-commit-config.yaml`
**Hooks**:
- `black` (code formatting)
- `flake8` (linting)
- `mypy` (type checking)
- `isort` (import sorting)

**Effort**: 1 hour

---

### P9.3: Embedding Quality Metrics

**New Script**: `scripts/analyze_embeddings.py`
**Metrics**:
- Embedding distribution (mean, std)
- Nearest neighbor distribution
- Cluster analysis
- Outlier detection

**Purpose**: Data quality insights.

**Effort**: 3-4 hours

---

### P9.4: Incremental Update Support

**Feature**: Add new cards without full rebuild.

**Approach**:
- Track Scryfall update timestamps
- Download only new/changed cards
- Append to existing index
- Rebuild FAISS index (fast with pre-computed embeddings)

**Effort**: 4-6 hours

---

## üìã Implementation Roadmap

### Phase 1: Critical Fixes ‚úÖ COMPLETED
**Goal**: Fix correctness issues and basic usability problems.
**Completed**: 2025-10-13

- ‚úÖ P1.1: Fix cosine similarity calculation
- ‚úÖ P1.2: Query path CLI argument
- ‚úÖ P1.3: Export script CLI arguments
- ‚úÖ P3.4: Output directory validation (implemented in export_for_browser.py)

**Remaining from original Phase 1**:
- ‚¨ú P8.1: Pin CLIP commit hash (5 min)

---

### Phase 2: User Experience Improvements (2-3 hours) üü†
**Goal**: Maximize accuracy, query speed, and minimize browser DB size.

- ‚¨ú P2.1: Use higher quality images (PNG priority) (2 min) - **Better accuracy**
- ‚¨ú P2.2: Increase image resolution to 384 (2 min) - **10-20% better accuracy**
- ‚¨ú P2.3: Implement HNSW index (15 min) - **10-100x faster queries, smaller index**
- ‚¨ú P2.4: int8 quantization for browser (1 hour) - **50% smaller download**
- ‚¨ú P3.1: Add logging for failures (20 min)
- ‚¨ú P3.2: Build summary statistics (10 min)

**Total**: ~2 hours, **massive user experience gains**

---

### Phase 3: Observability & Quality (4-6 hours) üü°
**Goal**: Production-ready error handling and code quality.

- ‚úÖ P3.3: Validate downloaded images (10 min)
- ‚úÖ P4.1: Extract device selection utility (15 min)
- ‚úÖ P4.2: Add type hints (1-2 hours)
- ‚úÖ P4.3: Configurable image preference (15 min)
- ‚úÖ P5.1: Unit tests for core functions (2-3 hours)

**Total**: ~4-5 hours

---

### Phase 4: Testing & Stability (4-6 hours) ‚ö™
**Goal**: Automated verification and reliability.

- ‚úÖ P5.2: Integration test for pipeline (1 hour)
- ‚úÖ P5.3: Data validation script (1 hour)
- ‚úÖ P2.3: HNSW index for large datasets (30 min)
- ‚úÖ P7.1: Troubleshooting documentation (30 min)
- ‚úÖ P7.2: Performance benchmarks (1 hour)

**Total**: ~4 hours

---

### Phase 5: Advanced Features (8+ hours) üîµ‚ö´üí°
**Goal**: Enhanced workflows and developer experience.

- ‚úÖ P6.1: YAML configuration support (2 hours)
- ‚úÖ P6.2: Resume/incremental builds (3-4 hours)
- ‚úÖ P7.3: Document browser integration (10 min)
- ‚úÖ P8.2: Conda lock files (30 min)
- ‚úÖ P9.1: Docker support (2-3 hours)
- ‚úÖ P9.2: Pre-commit hooks (1 hour)
- ‚úÖ P9.3: Embedding quality metrics (3-4 hours)
- ‚úÖ P9.4: Incremental update support (4-6 hours)

**Total**: ~16-20 hours for all advanced features

---

## üéØ Quick Start Recommendations

**User Priorities**: 1) Accuracy from blurry images, 2) Query speed, 3) Browser DB size

**If you have 5 minutes**: Do P2.1 + P2.2 (Quick wins)
- ‚úÖ Switch to PNG images for better quality
- ‚úÖ Increase resolution to 384
- **Impact**: 10-20% better accuracy on blurry images

**If you have 30 minutes**: Add P2.3 (HNSW index)
- ‚úÖ All quick accuracy improvements
- ‚úÖ 10-100x faster queries
- ‚úÖ Smaller index file
- **Impact**: Massive query speed improvement + better accuracy

**If you have 2 hours**: Complete Phase 2
- ‚úÖ All accuracy improvements
- ‚úÖ Fast queries with HNSW
- ‚úÖ 50% smaller browser download (int8 quantization)
- ‚úÖ Better observability
- **Impact**: Production-ready user experience

**If you have a day**: Do Phases 2-3
- ‚úÖ All user experience improvements
- ‚úÖ Production-ready error handling
- ‚úÖ Clean, maintainable code
- ‚úÖ Basic test coverage

**For maximum accuracy**: Consider P2.5 (ViT-L/14)
- Only if ViT-B/32 accuracy is insufficient
- Trade-off: 50% larger browser download, slower queries

---

## Notes

- All SPEC references link to `SPEC.md` for traceability
- Effort estimates are approximate for a developer familiar with the codebase
- Priority levels are suggestions; adjust based on actual needs
- Some improvements may conflict; review before implementing multiple

---

## Change Log

- **2025-10-13 v1.3**: Completely rewrote Priority 2 based on user priorities (accuracy > query speed > DB size). Removed build-time optimizations (parallel downloads, batch size tuning). Added accuracy improvements (PNG images, higher resolution), HNSW index for query speed, int8 quantization for smaller DB, and optional ViT-L/14 for maximum accuracy. Updated roadmap and quick-start recommendations.
- **2025-10-13 v1.2**: Marked P1.1, P1.2, P1.3 as completed; moved to "Completed Improvements" section
- **2025-10-13 v1.1**: Reorganized by priority, most critical first; added emojis and quick-start guide
- **2025-10-13 v1.0**: Initial version based on code review
