# Feature Specification: MTG Image Database and Frontend Integration

**Feature Branch**: `010-ensure-mtg-image`  
**Created**: 2025-10-16  
**Status**: Draft  
**Input**: User description: "Ensure mtg-image-db model and frontend integration work seamlessly together by validating data contracts, embedding format compatibility, and end-to-end query flow from webcam capture through SlimSAM card extraction to CLIP embedding and similarity search"

## User Scenarios & Testing *(mandatory)*

### User Story 1 - Data Contract Validation (Priority: P1)

A developer exports embeddings from the mtg-image-db package and loads them in the web frontend. The system validates that the binary format, metadata structure, and quantization parameters match exactly between producer and consumer, preventing runtime errors and data corruption.

**Why this priority**: This is foundational - without correct data contracts, the entire integration fails. All other features depend on this working correctly.

**Independent Test**: Can be fully tested by running the export script, loading artifacts in the browser, and verifying that shape, dtype, scale factor, and record count all match without errors.

**Acceptance Scenarios**:

1. **Given** embeddings are exported as int8 with scale factor 127, **When** the frontend loads `embeddings.i8bin` and `meta.json`, **Then** the system validates file size equals `N * 512` bytes and metadata version is "1.0"
2. **Given** `meta.json` contains quantization metadata, **When** the frontend dequantizes embeddings, **Then** vectors have L2 norm approximately 1.0 (within ±0.008 quantization error)
3. **Given** mismatched file sizes or record counts, **When** the frontend attempts to load artifacts, **Then** the system throws a clear error message indicating the specific mismatch

---

### User Story 2 - End-to-End Card Identification Flow (Priority: P2)

A player clicks on a card visible in their webcam stream. The system extracts the card region using SlimSAM, rectifies it to a canonical aspect ratio, embeds it using CLIP, searches against the preloaded database, and returns the top matching card with metadata.

**Why this priority**: This validates the complete integration pipeline from capture to identification, ensuring all components work together correctly.

**Independent Test**: Can be tested by starting the webcam (or using the mocked web stream at `apps/web/tests/assets/card_demo.webm` shown by default in development), clicking on a visible card, and verifying that the system returns correct card identification with name, set, and Scryfall link. E2E tests can use the mocked stream for automated verification.

**Acceptance Scenarios**:

1. **Given** a webcam stream showing a physical MTG card, **When** the user clicks on the card, **Then** SlimSAM segments the card region and extracts a perspective-corrected crop
2. **Given** a rectified card image, **When** the system embeds it using CLIP, **Then** the embedding is a 512-dimensional L2-normalized vector
3. **Given** a query embedding, **When** the system searches the database, **Then** it returns the top-1 match (single best result) with cosine similarity score
4. **Given** a search result, **When** displayed to the user, **Then** it shows card name, set code, thumbnail image, and Scryfall link

---

### User Story 3 - Embedding Format Compatibility (Priority: P3)

The system ensures that embeddings generated by the Python CLIP model in mtg-image-db are compatible with the browser-based CLIP model in the frontend, producing consistent similarity scores for the same query images.

**Why this priority**: This ensures search quality and consistency between offline Python queries and online browser queries.

**Independent Test**: Can be tested by embedding the same image in both Python and browser environments and verifying that the resulting vectors have high cosine similarity (>0.99).

**Acceptance Scenarios**:

1. **Given** the same card image, **When** embedded in Python using `Xenova/clip-vit-base-patch32` and in the browser using Transformers.js, **Then** the resulting embeddings have cosine similarity > 0.99
2. **Given** a query image, **When** searched in both Python FAISS and browser similarity search, **Then** the top-1 result is identical
3. **Given** L2-normalized embeddings, **When** computing similarity, **Then** cosine similarity equals dot product (no additional normalization needed)

---

### Edge Cases

- What happens when `embeddings.i8bin` file size doesn't match `shape[0] * shape[1]` in `meta.json`?
- What happens when `meta.json` uses an old format (array instead of object with version field)?
- How does the system handle missing required metadata fields (`name`, `set`, `image_url`, `card_url`)?
- What happens when SlimSAM fails to detect a card region after a click?
- How does the system handle webcam frames with poor lighting, blur, or extreme perspective angles?
- What happens when the browser doesn't support WebGPU and falls back to WebGL or WASM?
- How does the system handle quantization error accumulation in similarity scores?
- How does the SlimSAM detector integrate with existing detector switching logic (alongside OpenCV, DETR and OWL-ViT)?
- How does the system handle users who have explicitly selected OpenCV as their detector preference?

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: System MUST validate that `embeddings.i8bin` file size equals `shape[0] * shape[1]` bytes from `meta.json`
- **FR-002**: System MUST validate that `meta.json` contains version "1.0" with required fields: `version`, `quantization`, `shape`, `records`
- **FR-003**: System MUST validate that `records.length` equals `shape[0]` in `meta.json`
- **FR-004**: System MUST throw clear error messages for data contract violations (file size mismatch, metadata count mismatch, unsupported dtype, missing required fields)
- **FR-005**: System MUST dequantize int8 embeddings to float32 using formula `float32_value = int8_value / 127.0`
- **FR-006**: System MUST NOT re-normalize embeddings after dequantization (vectors already L2-normalized before quantization)
- **FR-007**: System MUST compute cosine similarity using dot product on L2-normalized vectors
- **FR-008**: System MUST implement SlimSAM card extraction as a new detector that conforms to the existing `CardDetector` interface (alongside existing detectors)
- **FR-009**: System MUST integrate SlimSAM segmentation with CLIP embedding pipeline using `Xenova/slimsam` via Transformers.js
- **FR-009a**: System MUST pass extracted card canvas from SlimSAM to CLIP embedder without intermediate file I/O
- **FR-010**: System MUST use the same CLIP model (`Xenova/clip-vit-base-patch32`) via Transformers.js in both Python export and browser query
- **FR-011**: System MUST preserve card aspect ratio (88.9mm × 63.5mm = 1.4 ratio) during perspective correction
- **FR-012**: System MUST return the top-1 result (single best match) with metadata including `name`, `set`, `image_url`, `card_url`, and `scryfall_uri`
- **FR-013**: System MUST handle WebGPU unavailability by falling back to WebGL or WASM for both SlimSAM and CLIP
- **FR-014**: System MUST validate that all required metadata fields are present before displaying results
- **FR-015**: System MUST update the `DetectorType` to include 'slimsam' as a valid detector option (keeping 'opencv', 'detr', 'owl-vit')
- **FR-016**: System MUST set 'slimsam' as the default detector in the application configuration
- **FR-017**: When SlimSAM fails to detect a card region, system MUST display a non-blocking notification with retry guidance and allow the user to click again immediately without requiring dismissal or reset
- **FR-018**: System MUST log all validation errors and detection failures to browser console with structured format including error type, context, and timestamp

### Key Entities

- **Embedding Database**: Binary file containing int8-quantized 512-dimensional vectors for all MTG cards, with accompanying metadata JSON containing quantization parameters, shape information, and per-card records
- **Query Pipeline**: End-to-end flow from webcam capture → SlimSAM segmentation → perspective correction → CLIP embedding → similarity search → result display
- **Data Contract**: Formal specification of binary format (int8, little-endian, row-major), metadata schema (version 1.0 JSON), quantization parameters (scale factor 127), and error handling requirements
- **Card Detector Interface**: Abstract interface (`CardDetector`) defining initialization, detection, status reporting, and cleanup methods that all detector implementations must conform to (including OpenCV, SlimSAM, DETR, and OWL-ViT)
- **SlimSAM Detector**: New detector implementation that works alongside existing detectors, conforming to `CardDetector` interface, using point-prompt segmentation to extract card regions from webcam frames
- **Card Extraction**: Process of detecting card region from webcam frame using SlimSAM point prompt, refining corners, enforcing aspect ratio, and warping to canonical rectangle
- **Similarity Search**: Computation of cosine similarity via dot product on L2-normalized vectors, returning top-K matches sorted by descending score

## Clarifications

### Session 2025-10-16

- Q: When SlimSAM fails to detect a card region after a user click, what should the system do? → A: Show a non-blocking notification with retry guidance and allow immediate retry
- Q: What is the maximum acceptable latency for SlimSAM card segmentation (from click to extracted canvas)? → A: 500 milliseconds
- Q: How should the system handle the transition from OpenCV to SlimSAM detector for existing users? → A: Keep OpenCV detector and add SlimSAM as a new detector option, making SlimSAM the default
- Q: What is the default number of top results (K) to return from similarity search? → A: 1 result
- Q: Should validation errors and detection failures be logged for debugging and monitoring? → A: Log errors to browser console with structured format for developer debugging

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: Loading artifacts in the browser completes without errors when data contracts are satisfied (100% success rate for valid data)
- **SC-002**: Loading artifacts throws specific, actionable error messages for all contract violations (file size mismatch, metadata mismatch, unsupported dtype, missing fields)
- **SC-003**: End-to-end card identification from webcam click to result display completes in under 3 seconds on modern hardware
- **SC-003a**: SlimSAM card segmentation (from click to extracted canvas) completes in under 500 milliseconds on modern hardware
- **SC-004**: Embedding the same image in Python and browser produces vectors with cosine similarity > 0.99
- **SC-005**: Top-1 search result is identical between Python FAISS and browser similarity search for the same query
- **SC-006**: System successfully identifies cards under varied conditions (different lighting, angles, distances) with >80% accuracy for top-1 match
- **SC-007**: Quantization error (L2 norm deviation from 1.0) remains within ±0.008 after dequantization
- **SC-008**: System handles WebGPU unavailability gracefully by falling back to WebGL/WASM without user intervention
