<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>MTG Commander Card Detection</title>
  <style>
    body { padding-top: 500px; }
    #video, #overlay {
      position: absolute;
      top: 0; left: 0;
      width: 640px; height: 480px;
      border: 1px solid black;
    }
    #overlay {
      cursor: pointer; /* show pointer on hover */
      z-index: 1;
    }
    #video { z-index: 0; }
    #cropped {
      margin-top: 500px;
      border: 1px solid black;
      width: 223px;  /* approx card aspect ratio 3.5" x 2.5" scaled */
      height: 310px;
    }
    #controls {
      margin-top: 10px;
    }
    #results {
      margin-top: 16px;
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(220px, 1fr));
      gap: 12px;
    }
    .result-card {
      display: flex;
      gap: 8px;
      padding: 8px;
      border: 1px solid #ddd;
      border-radius: 8px;
      background: #fafafa;
      align-items: center;
    }
    .result-card img {
      width: 80px;
      height: 112px;
      object-fit: cover;
      border-radius: 4px;
      border: 1px solid #ccc;
    }
    .result-meta {
      display: flex;
      flex-direction: column;
    }
    .muted { color: #666; font-size: 12px; }
    #camControls { position: relative; z-index: 10; }
    #controls { position: relative; z-index: 10; }
    #debug { position: relative; z-index: 10; }
    #results { position: relative; z-index: 10; }
  </style>
</head>
  <body>
  <video id="video" autoplay muted playsinline width="640" height="480"></video>
  <canvas id="overlay" width="640" height="480" ></canvas>
  <!-- Hidden canvas to capture full-resolution frames from the video for high-quality crops -->
  <canvas id="fullRes" style="display:none;"></canvas>
  <div style="position: relative; margin-top: 490px;">
    <label for="cameraSelect">Camera:</label>
    <select id="cameraSelect"></select>
  </div>
  <br />
  <div id="camControls" style="display:flex; flex-wrap:wrap; gap:16px; align-items:center;">
    <label><input type="checkbox" id="manualFocusToggle" /> Manual focus</label>
    <label>Focus distance <input type="range" id="focusRange" min="0" max="1" step="0.01" disabled /></label>
    <label>Exposure comp <input type="range" id="exposureComp" min="-5" max="5" step="0.1" disabled /></label>
  </div>
  <br />
  <canvas id="cropped" width="446" height="620"></canvas>
  <div id="controls">
    <button id="identifyBtn">Identify</button>
    <span id="statusText" class="muted"></span>
  </div>
  <div id="debug">
    <div class="muted">Name ROI preview (what OCR sees):</div>
    <canvas id="nameRoi" style="border:1px solid #ccc; max-width: 100%; image-rendering: pixelated;"></canvas>
    <div id="ocrText" class="muted"></div>
  </div>
  <div id="results"></div>

  <script src="https://unpkg.com/tesseract.js@4.0.2/dist/tesseract.min.js"></script>
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()"></script>

  <script>

    let video = document.getElementById('video');
    let overlay = document.getElementById('overlay');
    // Use willReadFrequently for better performance on frequent pixel reads
    let overlayCtx = overlay.getContext('2d', { willReadFrequently: true });
    let croppedCanvas = document.getElementById('cropped');
    const fullResCanvas = document.getElementById('fullRes');
    let fullResCtx = fullResCanvas.getContext('2d', { willReadFrequently: true });
    // Camera controls
    const manualFocusToggle = document.getElementById('manualFocusToggle');
    const focusRange = document.getElementById('focusRange');
    const exposureComp = document.getElementById('exposureComp');

    let croppedCtx = croppedCanvas.getContext('2d');
    overlayCtx.imageSmoothingEnabled = true;
    overlayCtx.imageSmoothingQuality = 'high';

    // OpenCV Mats
    let src, gray, blurred, edged;
    let contours, hierarchy;

    // Detected cards as arrays of 4 points [{x,y}, ...]
    let detectedCards = [];

    // Minimum area of card contour to filter noise
    const MIN_CARD_AREA = 4000;

    // Flag for OpenCV ready
    let cvReady = false;
    // Media stream and device tracking
    let currentStream = null;
    let currentDeviceId = null;
    let animationStarted = false;

    function onOpenCvReady() {
      cvReady = true;
      console.log('OpenCV.js is ready');
      startVideo();
    }

    async function startVideo(deviceId = null) {
      try {
        // Stop previous stream if any
        if (currentStream) {
          currentStream.getTracks().forEach(t => t.stop());
          currentStream = null;
        }

        const constraints = {
          audio: false,
          video: deviceId
            ? { deviceId: { exact: deviceId }, width: { ideal: 1920 }, height: { ideal: 1080 } }
            : { width: { ideal: 1920 }, height: { ideal: 1080 } }
        };

        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        currentStream = stream;
        video.srcObject = stream;

        // Track actual device in use
        const track = stream.getVideoTracks()[0];
        const settings = track.getSettings ? track.getSettings() : {};
        currentDeviceId = settings.deviceId || deviceId;
        // Initialize camera controls UI with capabilities
        setupCameraControls(track);

        // Try to apply exact constraints for higher resolution and stabilize exposure/focus if supported
        try {
          await track.applyConstraints({
            width: { ideal: 1920 },
            height: { ideal: 1080 },
            advanced: [
              { focusMode: 'continuous' },
              { whiteBalanceMode: 'continuous' },
              { exposureMode: 'continuous' }
            ]
          });
        } catch (e) {
          console.warn('Could not apply advanced constraints:', e);
        }
        // Re-run setup in case capabilities updated after constraints
        setupCameraControls(track);

        // Populate/refresh camera list after permission is granted
        populateCameraSelect();

        video.onloadedmetadata = () => {
          video.play();
          if (!src) {
            initOpenCVMats();
          }
          // Set full-res canvas to actual video resolution for best-quality crops
          if (video.videoWidth && video.videoHeight) {
            fullResCanvas.width = video.videoWidth;
            fullResCanvas.height = video.videoHeight;
          }
          if (!animationStarted) {
            animationStarted = true;
            requestAnimationFrame(detectCards);
          }
        };
      } catch (err) {
        alert('Error accessing webcam: ' + err);
      }
    }

    async function getCameras() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      return devices.filter(d => d.kind === 'videoinput');
    }

    async function populateCameraSelect() {
      try {
        const select = document.getElementById('cameraSelect');
        if (!select) return;
        const cameras = await getCameras();
        const prevValue = select.value;
        select.innerHTML = '';
        cameras.forEach((cam, idx) => {
          const opt = document.createElement('option');
          opt.value = cam.deviceId;
          opt.text = cam.label || `Camera ${idx + 1}`;
          select.appendChild(opt);
        });
        // Keep selection if possible, otherwise use current device
        if (prevValue && [...select.options].some(o => o.value === prevValue)) {
          select.value = prevValue;
        } else if (currentDeviceId && [...select.options].some(o => o.value === currentDeviceId)) {
          select.value = currentDeviceId;
        }
      } catch (e) {
        console.warn('Could not populate camera list:', e);
      }
    }

    function setupCameraControls(track) {
      if (!track || !track.getCapabilities) return;
      const caps = track.getCapabilities();
      // Focus distance
      if (caps.focusMode && caps.focusMode.includes('manual') && typeof caps.focusDistance !== 'undefined') {
        focusRange.disabled = false;
        focusRange.min = caps.focusDistance?.min ?? 0;
        focusRange.max = caps.focusDistance?.max ?? 1;
        focusRange.step = caps.focusDistance?.step ?? 0.01;
        manualFocusToggle.disabled = false;
      } else {
        focusRange.disabled = true;
        // Keep checkbox enabled so user can try; we'll show a status if unsupported
        manualFocusToggle.disabled = false;
      }
      // Exposure compensation
      if (typeof caps.exposureCompensation !== 'undefined') {
        exposureComp.disabled = false;
        const ec = caps.exposureCompensation;
        exposureComp.min = ec.min ?? -5;
        exposureComp.max = ec.max ?? 5;
        exposureComp.step = ec.step ?? 0.1;
      } else {
        exposureComp.disabled = true;
      }

      // Wire events
      manualFocusToggle?.addEventListener('change', async () => {
        try {
          if (manualFocusToggle.checked) {
            await track.applyConstraints({ advanced: [{ focusMode: 'manual', focusDistance: Number(focusRange.value) }] });
            setStatus('Manual focus requested. Adjust the slider and watch sharpness.');
          } else {
            await track.applyConstraints({ advanced: [{ focusMode: 'continuous' }] });
            setStatus('Continuous autofocus enabled.');
          }
        } catch (e) {
          console.warn('Applying focus mode failed:', e);
          setStatus('Manual focus not supported by this browser/camera. Try vendor app or Chrome.');
        }
      });
      focusRange?.addEventListener('input', async () => {
        if (!manualFocusToggle.checked) return;
        try { await track.applyConstraints({ advanced: [{ focusDistance: Number(focusRange.value) }] }); }
        catch (e) { console.warn('Setting focusDistance failed:', e); }
      });
      exposureComp?.addEventListener('input', async () => {
        try { await track.applyConstraints({ advanced: [{ exposureCompensation: Number(exposureComp.value) }] }); }
        catch (e) { console.warn('Setting exposureCompensation failed:', e); }
      });
    }

    function initOpenCVMats() {
      src = new cv.Mat(overlay.height, overlay.width, cv.CV_8UC4);
      gray = new cv.Mat();
      blurred = new cv.Mat();
      edged = new cv.Mat();

      contours = new cv.MatVector();
      hierarchy = new cv.Mat();
    }

    // Utility to order 4 points: top-left, top-right, bottom-right, bottom-left
    function orderPoints(pts) {
      // Sort by x coordinate
      pts.sort((a, b) => a.x - b.x);
      let leftMost = pts.slice(0, 2);
      let rightMost = pts.slice(2, 4);

      leftMost.sort((a, b) => a.y - b.y);
      rightMost.sort((a, b) => a.y - b.y);

      return [leftMost[0], rightMost[0], rightMost[1], leftMost[1]];
    }

    function drawPolygon(ctx, points, color = 'lime', lineWidth = 3) {
      ctx.strokeStyle = color;
      ctx.lineWidth = lineWidth;
      ctx.beginPath();
      ctx.moveTo(points[0].x, points[0].y);
      for (let i = 1; i < points.length; i++) {
        ctx.lineTo(points[i].x, points[i].y);
      }
      ctx.closePath();
      ctx.stroke();
    }

    function detectCards() {
      if (!cvReady) return;

      overlayCtx.clearRect(0, 0, overlay.width, overlay.height);
      detectedCards = [];

      // Draw video frame onto overlay canvas to get pixel data
      overlayCtx.drawImage(video, 0, 0, overlay.width, overlay.height);
      let imageData = overlayCtx.getImageData(0, 0, overlay.width, overlay.height);

      src.data.set(imageData.data);

      // Preprocessing for contour detection
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
      cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);
      cv.Canny(blurred, edged, 75, 200);

      cv.findContours(edged, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);

      for (let i = 0; i < contours.size(); i++) {
        let contour = contours.get(i);
        let approx = new cv.Mat();
        cv.approxPolyDP(contour, approx, 0.02 * cv.arcLength(contour, true), true);

        if (approx.rows === 4) {
          let area = cv.contourArea(approx);
          if (area > MIN_CARD_AREA) {
            let pts = [];
            for (let j = 0; j < 4; j++) {
              let ptData = approx.intPtr(j);
              pts.push({ x: ptData[0], y: ptData[1] });
            }
            let ordered = orderPoints(pts);
            detectedCards.push(ordered);

            // Draw polygon on overlay canvas
            drawPolygon(overlayCtx, ordered);
          }
        }

        approx.delete();
        contour.delete();
      }

      // Do NOT delete contours and hierarchy here; reuse them each frame!

      requestAnimationFrame(detectCards);
    }

    // Crop the detected card nearest to the clicked point and draw on cropped canvas
    function cropCardAt(x, y) {
      if (detectedCards.length === 0) return;

      // Find the polygon closest to click point
      let closestIndex = -1;
      let minDist = Infinity;

      for (let i = 0; i < detectedCards.length; i++) {
        let poly = detectedCards[i];
        // Calculate centroid of polygon
        let cx = 0, cy = 0;
        for (let p of poly) {
          cx += p.x;
          cy += p.y;
        }
        cx /= poly.length;
        cy /= poly.length;
        let dist = Math.hypot(cx - x, cy - y);
        if (dist < minDist) {
          minDist = dist;
          closestIndex = i;
        }
      }

      if (closestIndex === -1) return;

      let card = detectedCards[closestIndex];

      // Draw current full-resolution frame
      if (video.videoWidth && video.videoHeight) {
        fullResCtx.drawImage(video, 0, 0, fullResCanvas.width, fullResCanvas.height);
      }
      const frImage = fullResCtx.getImageData(0, 0, fullResCanvas.width, fullResCanvas.height);
      const frMat = cv.matFromImageData(frImage);

      // Map overlay points (640x480) to full-res video space
      const scaleX = fullResCanvas.width / overlay.width;
      const scaleY = fullResCanvas.height / overlay.height;
      const coords = [
        card[0].x * scaleX, card[0].y * scaleY,
        card[1].x * scaleX, card[1].y * scaleY,
        card[2].x * scaleX, card[2].y * scaleY,
        card[3].x * scaleX, card[3].y * scaleY,
      ];
      // Compute perspective transform to get a top-down view of the card from full-res frame
      let srcTri = cv.matFromArray(4, 1, cv.CV_32FC2, coords);
      let dstTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
        0, 0,
        croppedCanvas.width, 0,
        croppedCanvas.width, croppedCanvas.height,
        0, croppedCanvas.height,
      ]);

      let M = cv.getPerspectiveTransform(srcTri, dstTri);

      let dst = new cv.Mat();
      cv.warpPerspective(frMat, dst, M, new cv.Size(croppedCanvas.width, croppedCanvas.height));

      // Show cropped card on the cropped canvas
      let imgData = new ImageData(new Uint8ClampedArray(dst.data), dst.cols, dst.rows);
      croppedCtx.putImageData(imgData, 0, 0);

      // Clean up
      srcTri.delete(); dstTri.delete(); M.delete(); dst.delete(); frMat.delete();
    }

    // Handle click on overlay to crop card near the clicked point
    overlay.addEventListener('click', (event) => {
      // Get click relative to canvas
      const rect = overlay.getBoundingClientRect();
      const x = event.clientX - rect.left;
      const y = event.clientY - rect.top;
      cropCardAt(x, y);
    });

    // Camera selector change handler
    const cameraSelect = document.getElementById('cameraSelect');
    if (cameraSelect) {
      cameraSelect.addEventListener('change', (e) => {
        const id = e.target.value;
        if (id && id !== currentDeviceId) {
          startVideo(id);
        }
      });
    }

    // Update camera list on device changes (plug/unplug)
    if (navigator.mediaDevices && navigator.mediaDevices.addEventListener) {
      navigator.mediaDevices.addEventListener('devicechange', () => {
        populateCameraSelect();
      });
    }

    // Cleanup OpenCV mats when leaving the page
    window.addEventListener('beforeunload', () => {
      if (src) src.delete();
      if (gray) gray.delete();
      if (blurred) blurred.delete();
      if (edged) edged.delete();
      if (contours) contours.delete();
      if (hierarchy) hierarchy.delete();
    });

    // =====================
    // Identification logic
    // =====================
    const identifyBtn = document.getElementById('identifyBtn');
    const resultsEl = document.getElementById('results');
    const statusEl = document.getElementById('statusText');
    const nameRoiCanvas = document.getElementById('nameRoi');
    const ocrTextEl = document.getElementById('ocrText');
    let ocrBusy = false;
    // Catalog of official card names for fuzzy AI-like correction
    let CARD_NAME_CATALOG = null; // array of strings
    let CATALOG_LOADING = null;

    function setStatus(text) {
      if (statusEl) statusEl.textContent = text || '';
    }

    function matToImageData(mat) {
      // If single-channel, expand to RGBA for Canvas compatibility
      let rgba;
      if (mat.type() === cv.CV_8UC1) {
        rgba = new cv.Mat();
        cv.cvtColor(mat, rgba, cv.COLOR_GRAY2RGBA);
      } else if (mat.type() === cv.CV_8UC3) {
        rgba = new cv.Mat();
        cv.cvtColor(mat, rgba, cv.COLOR_RGB2RGBA);
      } else if (mat.type() === cv.CV_8UC4) {
        rgba = mat.clone();
      } else {
        // Fallback: try convert to RGBA
        rgba = new cv.Mat();
        cv.cvtColor(mat, rgba, cv.COLOR_RGBA2RGBA);
      }
      const img = new ImageData(new Uint8ClampedArray(rgba.data), rgba.cols, rgba.rows);
      rgba.delete();
      return img;
    }

    function preprocessForOCRFromCanvas(canvas) {
      // Read canvas -> Mat
      const ctx = canvas.getContext('2d');
      const imgData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      let m = cv.matFromImageData(imgData);

      // Convert to gray
      let g = new cv.Mat();
      cv.cvtColor(m, g, cv.COLOR_RGBA2GRAY);

      // Denoise
      let dn = new cv.Mat();
      cv.bilateralFilter(g, dn, 5, 50, 50);

      // CLAHE (with fallbacks for Safari/opencv.js builds without CLAHE)
      let cl = new cv.Mat();
      if (typeof cv.createCLAHE === 'function') {
        let clahe = cv.createCLAHE(3.0, new cv.Size(8, 8));
        clahe.apply(dn, cl);
        clahe.delete();
      } else if (typeof cv.CLAHE === 'function') {
        // Some builds expose constructor directly
        let clahe = new cv.CLAHE(3.0, new cv.Size(8, 8));
        clahe.apply(dn, cl);
        clahe.delete();
      } else {
        // Fallback: standard histogram equalization
        cv.equalizeHist(dn, cl);
      }

      // Unsharp mask: sharp = 1.5*cl - 0.5*blur(cl)
      let blur = new cv.Mat();
      cv.GaussianBlur(cl, blur, new cv.Size(0, 0), 1);
      let sharp = new cv.Mat();
      cv.addWeighted(cl, 1.5, blur, -0.5, 0, sharp);

      // Upscale 2x for better OCR
      let up = new cv.Mat();
      cv.resize(sharp, up, new cv.Size(0, 0), 2, 2, cv.INTER_CUBIC);

      // Cleanup temp mats
      m.delete(); g.delete(); dn.delete(); cl.delete(); blur.delete(); sharp.delete();

      return up; // grayscale upscaled
    }

    function extractNameRoi(grayMat) {
      // grayMat is upscaled grayscale image of the rectified card
      const H = grayMat.rows;
      const W = grayMat.cols;
      const y0 = Math.max(0, Math.round(0.04 * H));
      const y1 = Math.min(H, Math.round(0.14 * H));
      const x0 = Math.max(0, Math.round(0.07 * W));
      const x1 = Math.min(W, Math.round(0.93 * W));
      const rect = new cv.Rect(x0, y0, Math.max(1, x1 - x0), Math.max(1, y1 - y0));
      let roi = grayMat.roi(rect);

      // Adaptive threshold for crisp text
      let bin = new cv.Mat();
      cv.adaptiveThreshold(roi, bin, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 15, 3);
      roi.delete();
      return bin; // binary image
    }

    function computeNameRoiSharpness(grayMat) {
      // Same ROI as extractNameRoi, compute variance of Laplacian
      const H = grayMat.rows;
      const W = grayMat.cols;
      const y0 = Math.max(0, Math.round(0.04 * H));
      const y1 = Math.min(H, Math.round(0.14 * H));
      const x0 = Math.max(0, Math.round(0.07 * W));
      const x1 = Math.min(W, Math.round(0.93 * W));
      const rect = new cv.Rect(x0, y0, Math.max(1, x1 - x0), Math.max(1, y1 - y0));
      let roi = grayMat.roi(rect);
      let lap = new cv.Mat();
      cv.Laplacian(roi, lap, cv.CV_64F);
      let mean = new cv.Mat();
      let stddev = new cv.Mat();
      cv.meanStdDev(lap, mean, stddev);
      const sigma = stddev.doubleAt(0, 0);
      const variance = sigma * sigma;
      roi.delete(); lap.delete(); mean.delete(); stddev.delete();
      return variance;
    }

    function showNameRoi(imgData) {
      if (!nameRoiCanvas) return;
      nameRoiCanvas.width = imgData.width;
      nameRoiCanvas.height = imgData.height;
      const ctx = nameRoiCanvas.getContext('2d');
      ctx.putImageData(imgData, 0, 0);
    }

    // ===== Helpers for multi-pass OCR and catalog matching =====
    function toImageDataFromMat(mat) {
      return matToImageData(mat);
    }

    function normalizeName(s) {
      return (s || '')
        .toLowerCase()
        .replace(/[^a-z0-9\-' ]/g, ' ')
        .replace(/\s+/g, ' ')
        .trim();
    }

    function levenshtein(a, b) {
      const m = a.length, n = b.length;
      if (m === 0) return n;
      if (n === 0) return m;
      const dp = new Array(n + 1);
      for (let j = 0; j <= n; j++) dp[j] = j;
      for (let i = 1; i <= m; i++) {
        let prev = dp[0];
        dp[0] = i;
        for (let j = 1; j <= n; j++) {
          const tmp = dp[j];
          const cost = a[i - 1] === b[j - 1] ? 0 : 1;
          dp[j] = Math.min(
            dp[j] + 1,
            dp[j - 1] + 1,
            prev + cost
          );
          prev = tmp;
        }
      }
      return dp[n];
    }

    async function loadCardNameCatalog() {
      if (CARD_NAME_CATALOG) return CARD_NAME_CATALOG;
      if (CATALOG_LOADING) return CATALOG_LOADING;
      CATALOG_LOADING = fetch('https://api.scryfall.com/catalog/card-names')
        .then(r => r.json())
        .then(j => Array.isArray(j.data) ? j.data : [])
        .catch(() => [])
        .then(arr => { CARD_NAME_CATALOG = arr; return CARD_NAME_CATALOG; });
      return CATALOG_LOADING;
    }

    function bestCatalogMatch(text, catalog) {
      const norm = normalizeName(text);
      if (!norm) return null;
      const first = norm[0];
      const pool = catalog.filter(name => normalizeName(name).startsWith(first)).slice(0, 5000);
      const candPool = pool.length ? pool : catalog;
      let best = null;
      let bestScore = Infinity;
      for (const name of candPool) {
        const nname = normalizeName(name);
        const dist = levenshtein(norm, nname);
        const rel = dist / Math.max(1, nname.length);
        if (rel < bestScore) { bestScore = rel; best = name; }
        if (bestScore === 0) break;
      }
      return { name: best, score: bestScore };
    }

    function generateRoiVariants(grayUpscaledMat) {
      // Build multiple variations of the name ROI for OCR robustness
      const variants = [];
      const H = grayUpscaledMat.rows, W = grayUpscaledMat.cols;
      const y0 = Math.max(0, Math.round(0.04 * H));
      const y1 = Math.min(H, Math.round(0.14 * H));
      const x0 = Math.max(0, Math.round(0.07 * W));
      const x1 = Math.min(W, Math.round(0.93 * W));
      const rect = new cv.Rect(x0, y0, Math.max(1, x1 - x0), Math.max(1, y1 - y0));
      const roi = grayUpscaledMat.roi(rect);

      // Adaptive threshold (small window)
      let m1 = new cv.Mat();
      cv.adaptiveThreshold(roi, m1, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 15, 3);
      variants.push({ label: 'adaptive15-3', imgData: toImageDataFromMat(m1) });

      // Adaptive threshold (larger window)
      let m2 = new cv.Mat();
      cv.adaptiveThreshold(roi, m2, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 31, 7);
      variants.push({ label: 'adaptive31-7', imgData: toImageDataFromMat(m2) });

      // Otsu global threshold
      let m3 = new cv.Mat();
      cv.threshold(roi, m3, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU);
      variants.push({ label: 'otsu', imgData: toImageDataFromMat(m3) });

      // Plain gray
      variants.push({ label: 'gray', imgData: toImageDataFromMat(roi) });

      m1.delete(); m2.delete(); m3.delete(); roi.delete();
      return variants;
    }

    async function ocrNameFromCanvas(canvas) {
      const pre = preprocessForOCRFromCanvas(canvas);
      // Variants of ROI for robustness
      const variants = generateRoiVariants(pre);
      // Render first variant for preview
      showNameRoi(variants[0].imgData);
      if (nameRoiCanvas && typeof nameRoiCanvas.scrollIntoView === 'function') {
        nameRoiCanvas.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
      }
      // Compute and display sharpness score on preprocessed gray
      const sharpness = computeNameRoiSharpness(pre);
      if (ocrTextEl) ocrTextEl.textContent = `Sharpness: ${sharpness.toFixed(0)}`;

      const names = [];
      for (const v of variants) {
        const off = document.createElement('canvas');
        off.width = v.imgData.width; off.height = v.imgData.height;
        const offCtx = off.getContext('2d');
        offCtx.putImageData(v.imgData, 0, 0);
        try {
          const result = await Tesseract.recognize(off, 'eng', {
            tessedit_pageseg_mode: 7,
            tessedit_char_whitelist: "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-' ,"
          });
          const text = (result?.data?.text || '').trim();
          names.push({ variant: v.label, text });
        } catch (e) {
          console.warn('OCR failed for variant', v.label, e);
        }
      }

      pre.delete();

      // Choose best match against catalog
      const catalog = await loadCardNameCatalog();
      let best = { text: '', variant: '', match: null };
      for (const n of names) {
        const san = normalizeName(n.text);
        if (!san) continue;
        const m = bestCatalogMatch(san, catalog);
        if (!m) continue;
        if (!best.match || m.score < best.match.score) best = { text: n.text, variant: n.variant, match: m };
      }
      // As fallback, return longest raw OCR if no match
      if (!best.match) {
        const longest = names.sort((a,b)=>b.text.length-a.text.length)[0];
        return longest ? longest.text : '';
      }
      // Show choice in debug
      if (ocrTextEl) ocrTextEl.textContent += ` | Variant: ${best.variant} | Best catalog: "${best.match.name}" (score ${(best.match.score||0).toFixed(2)})`;
      return best.match.name;
    }

    function clearResults() {
      resultsEl.innerHTML = '';
    }

    function renderCandidates(cands, sourceNote) {
      clearResults();
      if (!cands || cands.length === 0) {
        resultsEl.innerHTML = '<div class="muted">No candidates found.</div>';
        return;
      }
      for (const c of cands) {
        const div = document.createElement('div');
        div.className = 'result-card';
        const img = document.createElement('img');
        img.src = c.image_uris?.small || c.image_uris?.normal || c.image_uris?.png || (c.card_faces && c.card_faces[0]?.image_uris?.small) || '';
        const meta = document.createElement('div');
        meta.className = 'result-meta';
        const name = document.createElement('div');
        name.textContent = c.name;
        const set = document.createElement('div');
        set.className = 'muted';
        set.textContent = `${c.set_name || ''} • ${c.rarity || ''}`;
        meta.appendChild(name);
        meta.appendChild(set);
        div.appendChild(img);
        div.appendChild(meta);
        resultsEl.appendChild(div);
      }
      if (sourceNote) {
        const note = document.createElement('div');
        note.className = 'muted';
        note.textContent = sourceNote;
        resultsEl.prepend(note);
      }
    }

    async function scryfallLookup(nameGuess) {
      const q = (nameGuess || '').trim();
      if (q.length < 3) {
        return { candidates: [], note: 'Query too short for reliable match' };
      }
      // Try Named fuzzy first
      try {
        const r = await fetch(`https://api.scryfall.com/cards/named?fuzzy=${encodeURIComponent(q)}`);
        const j = await r.json();
        if (!j.object || j.object !== 'error') {
          return { candidates: [j], note: 'Named fuzzy match' };
        }
        // If ambiguous or not_found, fall through to search
      } catch (e) {
        console.warn('Named lookup failed:', e);
      }
      // Fallback: search endpoint, constrain and take only one
      try {
        const search = `name:${q} lang:en game:paper`;
        const url = `https://api.scryfall.com/cards/search?q=${encodeURIComponent(search)}&unique=cards&order=released&dir=desc`;
        const r2 = await fetch(url);
        const j2 = await r2.json();
        if (j2.object === 'list' && Array.isArray(j2.data) && j2.data.length) {
          return { candidates: [j2.data[0]], note: 'Search top result' };
        }
      } catch (e2) {
        console.warn('Search lookup failed:', e2);
      }
      return { candidates: [], note: '' };
    }

    async function identifyCard() {
      if (ocrBusy) return;
      ocrBusy = true;
      setStatus('OCR in progress…');
      clearResults();
      try {
        const text = await ocrNameFromCanvas(croppedCanvas);
        if (!text) {
          setStatus('No text recognized. Try re-cropping or improving focus.');
          ocrBusy = false;
          return;
        }
        // Show chosen text (already from catalog if matched)
        if (ocrTextEl) ocrTextEl.textContent += ` | Final text: "${text}"`;

        // Sanitize for fuzzy query to avoid odd control chars
        const sanitized = text.replace(/[^A-Za-z0-9\-' ,]/g, ' ').replace(/\s+/g, ' ').trim();
        console.log('Final OCR:', text);
        console.log('Final sanitized:', sanitized);

        if (!sanitized || sanitized.length < 3) {
          setStatus('Recognized text too short to query Scryfall. Try again with a clearer crop.');
          renderCandidates([], 'Query too short');
          return;
        }

        setStatus(`Recognized. Searching…`);
        const { candidates, note } = await scryfallLookup(sanitized);
        renderCandidates(candidates, note);
        setStatus('');
      } catch (e) {
        console.error(e);
        setStatus('Identification failed. See console.');
      } finally {
        ocrBusy = false;
      }
    }

    if (identifyBtn) {
      identifyBtn.addEventListener('click', identifyCard);
    }
  </script>
</body>
</html>
